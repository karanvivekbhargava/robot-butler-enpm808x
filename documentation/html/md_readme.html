<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Robot Butler ENPM808X: readme</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Robot Butler ENPM808X
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_readme.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">readme </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1 align="center">ENPM808X - <a class="el" href="class_robot.html" title="Class for robot. ">Robot</a> Butler </h1>
<p><a href="https://travis-ci.org/karanvivekbhargava/robot-butler-enpm808x"></a> <a href="https://coveralls.io/github/karanvivekbhargava/robot-butler-enpm808x?branch=master"></a> <a href="https://opensource.org/licenses/MIT"></a> </p>
<div class="image">
<img src="https://cdn.andnowuknow.com/mainStoryImage/robot_butler_aug_2014_banner.jpg" />
</div>
<p> Reference for image: <a href="http://www.savioke.com/">link</a> </p>
<h2><a class="el" href="class_robot.html" title="Class for robot. ">Robot</a> Overview</h2>
<p>The Butler product by Acme Robotics is one of its flagship products. It performs best for an environment where things are to be transported to and fro from one area to another. Equipped with a 16MP camera and the best of class custom lidar sensor, its the best offering one can hope for. The butler has intelligent algorithms running under its hood which allow it to percieve its environment by using these sensors. This allows the butler to avoid hitting obstacles and helps it serve you better.</p>
<h2>New Feature List</h2>
<p>We tirelessly work on our robots so that you don't have to. Our new offerings in software are included below.</p><ul>
<li>Estimation of object distances using camera data: While other companies are defining state of the art algorithms on the road, we do it in your workplace. Making our robots 30% less likely to crash into objects than our competitors.</li>
<li>Using lidar to map your environment: The butler records its surroundings in 3D so that it can see obstacles before they hit it.</li>
<li>Advanced data fusion algorithms: Our robots are cool but don't be fooled by their innocent appearance, they work super hard on the inside to crunch numbers faster than ever.</li>
<li>Path Planning: Using our custom sensors and the fusion technique, we can better plan the paths to avoid obstacles <hr/>
 <h2>The Camera</h2>
</li>
</ul>
<p>The butler has a 16MP front facing camera. Its camera module consists of an FPGA which can perform custom algorithms at a mind boggling pace. Once the input image arrives, the module does a perspective transform on it. This gives us a birds eye view which is then passed to a thresholder. The binarized image from the thresholder is then used to calculate the probabilities of hitting the nearby obstacles. We use a gaussian probability distribution to compute the same.</p>
<p>The images below show how the camera module is manupulating the data to translate it into a probability. The left image is the input, the center image is the perspective warped image and the right image is the thresholded image after warping. After this I'm checking the distances to obstacles with different headding directions. I can use these distances to obtain probabilties using a gaussian distribution. </p>
<div class="image">
<img src="data/output/1_original_resized.png"  width="270" height="200"/>
</div>
 <div class="image">
<img src="data/output/3_output_warped.png"  width="270" height="200"/>
</div>
 <div class="image">
<img src="data/output/4_output_warped_thresholded.png"  width="270" height="200"/>
</div>
 <h2>The Lidar</h2>
<p>The lidar gives a three dimensional point cloud representation of its surroundings. It uses this information and 'flattens' it out. This results in all the points being in some eucledean plane and the robot being the origin. It computes the distances from the obstacles and returns gaussian probabilitites to all the possible heading directions of the robot.</p>
<p>Example: Consider that we have a point from the point cloud as below. PS: The points are preprocessed to be in the heading directions that we are going to consider. </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;p = (1, 2, 3)</div></div><!-- fragment --><p> The points will be flattened at first, this results in the representation of the points on the ground (euclidean plane). </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;p_flattened = (1, 2)</div></div><!-- fragment --><p> We will then compute the distances of the points from the origin (this is where the robot will be at all times) </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;d = sqrt(1^2 + 2^2)</div></div><!-- fragment --><p> We then turn these distances into the probabilities of hitting an obstacle by </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;Probability = C*e^((d-mean)/(2*variance))</div></div><!-- fragment --><p> Where C is a normalization constant, mean is 0 and variance is tuned according to the data. The lidar outputs these probabilites.</p>
<h2>Sensor Fusion</h2>
<p>After the camera and lidar do the hard work of putting the information in a sensible format, the sensor fusion module takes the two readings and selects the higher probability of the two, for each heading direction. Although this might result in some noisy outputs, it gives a high probability of avoiding obstacles.</p>
<p>Example: If say we have the incoming probabilities given below where the probabilities correspond to heading directions -30, -20, -10, 10, 20, 30 degrees from current heading direction. </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;P_image = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6];</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;P_lidar = [0.6, 0.5, 0.4, 0.3, 0.2, 0,1];</div></div><!-- fragment --><p> Fused probability is given by </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;P_fusion = max(P_image, P_lidar)</div></div><!-- fragment --><p> Which gives us, </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;P_fusion = [0.6, 0.5, 0.4, 0.4, 0.5, 0.6];</div></div><!-- fragment --><h2>Path Planning</h2>
<p>The path planner uses the fused sensor output to determine what should be the next heading direction. This is done by selecting the heading direction which results in the least probability of hitting any obstacles.</p>
<p>Example: If the incoming fused probabilities are as given below </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;P_fused = [0.1, 0.2, 0.0, 0.01, 0.1, 0,3];</div></div><!-- fragment --><p> Then the path planner can be written mathematically as </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;direction = argmin_x( P_fused[x] )</div></div><!-- fragment --><p> Then the output of the path planner would be </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;direction = 2 (index of 0.0)</div></div><!-- fragment --><h2>The <a class="el" href="class_robot.html" title="Class for robot. ">Robot</a></h2>
<p>The robot is the class which uses all the other modules and creates instances of a camera, lidar, sensor fusion module and path planning module. It then uses the modules to run. </p>
<div class="image">
<img src="UML/initial/Activity_Diagram.jpg" />
</div>
 <hr/>
 <h2>SIP Overview</h2>
<p>Click this link to view the product backlog, time sheets, defect logs and release backlog - <a href="https://docs.google.com/spreadsheets/d/1WOvV6iL4gGOF8Qacwj2R3Lom71wziKXEf_UEhdGfOuY/edit?usp=sharing">link</a></p>
<p>Care has been taken to design the SIP tasks such that they have a direct relation to the previous tasks. This helps in better time estimation. For instance, the change in time taken for stub implementation is proportional to the change in time taken to implement the methods. This gave me a good idea to rethink about the allotment of time for future tasks. </p><hr/>
 <h2>Overview</h2>
<p>The butler software stack has the following dependencies:</p><ul>
<li>cmake</li>
<li>googletest</li>
<li>opencv</li>
</ul>
<p>## Standard install via command-line </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;git clone --recursive https://github.com/karanvivekbhargava/robot-butler-enpm808x</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;cd &lt;path to repository&gt;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;mkdir build</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;cd build</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;cmake ..</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;make</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;Run tests: ./test/cpp-test</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;Run program: ./app/shell-app</div></div><!-- fragment --><p>## Building for code coverage (for assignments beginning in Week 4) </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;sudo apt-get install lcov</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;cmake -D COVERAGE=ON -D CMAKE_BUILD_TYPE=Debug ../</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;make</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;make code_coverage</div></div><!-- fragment --><p> This generates a index.html page in the build/coverage sub-directory that can be viewed locally in a web browser.</p>
<h2>Working with Eclipse IDE</h2>
<h2>Installation</h2>
<p>In your Eclipse workspace directory (or create a new one), checkout the repo (and submodules) </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;mkdir -p ~/workspace</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;cd ~/workspace</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;git clone --recursive https://github.com/karanvivekbhargava/robot-butler-enpm808x</div></div><!-- fragment --><p>In your work directory, use cmake to create an Eclipse project for an [out-of-source build] of cpp-boilerplate</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;cd ~/workspace</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;mkdir -p boilerplate-eclipse</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;cd boilerplate-eclipse</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;cmake -G &quot;Eclipse CDT4 - Unix Makefiles&quot; -D CMAKE_BUILD_TYPE=Debug -D CMAKE_ECLIPSE_VERSION=4.7.0 -D CMAKE_CXX_COMPILER_ARG1=-std=c++14 ../cpp-boilerplate/</div></div><!-- fragment --><h2>Import</h2>
<p>Open Eclipse, go to File -&gt; Import -&gt; General -&gt; Existing Projects into Workspace -&gt; Select "boilerplate-eclipse" directory created previously as root directory -&gt; Finish</p>
<h1>Edit</h1>
<p>Source files may be edited under the "[Source Directory]" label in the Project Explorer.</p>
<h2>Build</h2>
<p>To build the project, in Eclipse, unfold boilerplate-eclipse project in Project Explorer, unfold Build Targets, double click on "all" to build all projects.</p>
<h2>Run</h2>
<ol type="1">
<li>In Eclipse, right click on the boilerplate-eclipse in Project Explorer, select Run As -&gt; Local C/C++ Application</li>
<li>Choose the binaries to run (e.g. shell-app, cpp-test for unit testing)</li>
</ol>
<h2>Debug</h2>
<ol type="1">
<li>Set breakpoint in source file (i.e. double click in the left margin on the line you want the program to break).</li>
<li>In Eclipse, right click on the boilerplate-eclipse in Project Explorer, select Debug As -&gt; Local C/C++ Application, choose the binaries to run (e.g. shell-app).</li>
<li>If prompt to "Confirm Perspective Switch", select yes.</li>
<li>Program will break at the breakpoint you set.</li>
<li>Press Step Into (F5), Step Over (F6), Step Return (F7) to step/debug your program.</li>
<li>Right click on the variable in editor to add watch expression to watch the variable in debugger window.</li>
<li>Press Terminate icon to terminate debugging and press C/C++ icon to switch back to C/C++ perspetive view (or Windows-&gt;Perspective-&gt;Open Perspective-&gt;C/C++).</li>
</ol>
<h2>Plugins</h2>
<ul>
<li><p class="startli">CppChEclipse</p>
<p class="startli">To install and run cppcheck in Eclipse</p><ol type="1">
<li>In Eclipse, go to Window -&gt; Preferences -&gt; C/C++ -&gt; cppcheclipse. Set cppcheck binary path to "/usr/bin/cppcheck".</li>
<li>To run CPPCheck on a project, right click on the project name in the Project Explorer and choose cppcheck -&gt; Run cppcheck.</li>
</ol>
</li>
<li><p class="startli">Google C++ Sytle</p>
<p class="startli">To include and use Google C++ Style formatter in Eclipse</p><ol type="1">
<li>In Eclipse, go to Window -&gt; Preferences -&gt; C/C++ -&gt; Code Style -&gt; Formatter. Import <a href="https://raw.githubusercontent.com/google/styleguide/gh-pages/eclipse-cpp-google-style.xml">eclipse-cpp-google-style</a> and apply.</li>
<li>To use Google C++ style formatter, right click on the source code or folder in Project Explorer and choose Source -&gt; Format</li>
</ol>
</li>
<li><p class="startli">Git</p>
<p class="startli">It is possible to manage version control through Eclipse and the git plugin, but it typically requires creating another project. If you're interested in this, try it out yourself. </p>
</li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
